# 机器学习及数据处理

## 模型的训练

![1760596818837](lecture8.assets/1760596818837.png)

根据上节课的内容，我们知道了模型训练的过程。具体而言，模型训练指的是通过优化算法 (Optimization Algorithm) 来调整模型的参数，使得模型在训练数据上的预测结果尽可能接近真实结果。模型的参数分为两种：

- 超参数 (Hyperparameter)：在训练之前设置的参数
  - 比如 KNN 中的 K 值
- 模型参数 (Model Parameter)：通过训练数据学习得到的参数
  - 比如线性回归中的权重和偏置

### 损失函数
  
通常我们使用损失函数来衡量模型的预测结果与真实结果之间的差距。损失函数计算出来的值叫做损失 (loss)。有很多种损失函数的形式

- 均方误差 (Mean Squared Error, MSE)：用于回归任务，计算预测值与真实值之间的平方差的平均值。
  - $$ \mathrm{MSE} = \frac{1}{N} \sum_{i=1}^{N} (y_i - \hat{y}_i)^2 $$
  - MSE 总是凸函数并且可微，因此易于优化
  - 对异常值敏感，因为平方项会放大较大的误差
- 均绝对误差 (Mean Absolute Error, MAE)：用于回归任务，计算预测值与真实值之间的绝对差的平均值。
  - $$ \mathrm{MAE} = \frac{1}{N} \sum_{i=1}^N | y_i - \hat{y}_i | $$
  - MAE 对异常值更不敏感，因为它使用绝对值而不是平方
  - MAE 在某些点不可微，可能会导致优化困难
- 交叉熵损失 (Cross-Entropy Loss)：用于分类任务，衡量预测的概率分布与真实类别之间的差异。
  - 二进制交叉熵 (Binary Cross Entropy)
    - $$ l = -\frac{1}{N}\sum_{i=1}^N (y_i\log\hat{y}_i + (1 - y_i)\log(1 - \hat{y}_i)) $$
    - 适用于二分类任务
  - 多类交叉熵 (Categorical Cross Entropy)
    - $$ l = -\sum_{i=1}^N \sum_{j=1}^K y_{i,j} \log(\hat{y}_{i,j}) $$
    - 可微，因此易于优化
    - 有多个局部最小值，可能会导致优化困难

在模型训练的过程中，首先需要选择使用哪种损失函数，之后在训练过程中最小化损失函数的值，最终得到一套最优的模型参数。比如，对于线性模型 $ y=ax+b$，$l(a,b) = \frac{1}{N}\sum_{j=1}^N(y_j - ax_j - b)^2$，训练的目标则是选择合适的参数得到 $\min l(a,b)$。

可以发现此时 $l(a,b)$ 是一个连续、可微的凸函数，因此可以使用梯度下降法 (Gradient Descent) 来进行优化。

### 梯度下降

梯度下降法是一种通过一阶导数和迭代法来寻找函数的局部最小值的办法。它的迭代方程是

$$
x_{k+1} = x_k - a_k \nabla f(x_k)
$$

其中，$x_k$ 是第 $k$ 次迭代的参数，$a_k$ 是学习率 (Learning Rate)，$\nabla f(x_k)$ 是函数 $f$ 在 $x_k$ 处的梯度。

使用梯度下降法来优化时，通常会先确定一个初始点 $x_0$，然后计算该点的梯度 $\nabla f(x_0)$，接着根据学习率 $a_0$ 来更新参数，得到新的参数 $x_1$。重复这个过程，直到满足停止条件，比如达到最大迭代次数或者梯度足够小。

![1760597997173](lecture8.assets/1760597997173.png)

在梯度下降算法中，我们需要计算梯度。有这么几种方式：

- Batch Gradient Descent (BGD)
  - 每次使用所有训练数据来计算梯度，然后通过均值来更新参数
  - 优点：梯度计算准确，收敛稳定
  - 缺点：计算量大，内存消耗高
- Stochastic Gradient Descent (SGD)
  - 每次随机选择一个训练样本来计算梯度，然后更新参数
  - 优点：计算量小，内存消耗低
  - 缺点：梯度计算不准确，收敛不稳定，更多次的模型更新和更多的计算量
- Mini-Batch Gradient Descent
  - 每次随机选择一小批训练样本来计算梯度，然后更新参数
  - 优点：在计算效率和梯度准确性之间取得平衡
  - 缺点：需要选择合适的批量大小
    - 这也是一个超参数，更小的值会类似 SGD，更大的值会类似 BGD
    - 通常选择 32

## 模型的测试

在上节课提到，模型使用训练集进行训练，使用测试集进行测试。测试集是从原始数据集中划分出来的一部分数据。在测试集中，预测的值和实际的值之间的误差叫预测误差 (Prediction Error)。

$$
\mathrm{Err} = \mathrm{Bias}^2 + \mathrm{Var} + \mathrel{Noice}
$$

- Bias：偏差，指的是模型预测值的期望与真实值之间的差异。
  - 偏差反映了模型对训练数据的拟合程度。高偏差通常意味着模型过于简单，无法捕捉数据的复杂模式，导致欠拟合 (Underfitting)。
  - 其与模型自身和训练过程都有关。
- Var：方差，指的是模型预测值的变化程度。
  - 方差反映了模型对训练数据的敏感程度。
  - 高方差通常意味着模型过于复杂，容易受到训练数据中噪声的影响，导致过拟合 (Overfitting)。
  - 其主要和训练过程有关。
- Noice：噪声，指的是数据中不可预测的随机误差。
  - 噪声是数据本身固有的，无法通过模型来消除。

### 偏差 (Bias)

高偏差的模型会导致在训练集和测试集中都会出现的高预测误差。这会导致模型对训练数据有很强的假设，以及欠拟合。

欠拟合指的是模型既不能很好地拟合训练数据，也不能很好地泛化到测试数据。

![1760598686765](lecture8.assets/1760598686765.png)

![1760598697225](lecture8.assets/1760598697225.png)

![1760599465582](lecture8.assets/1760599465582.png)

其典型特征是在训练集和测试集上市都有很差的表现，可以通过更换机器学习算法，以及提高训练时间来改善。

### 方差 (Variance)

方差指的是使用不同的训练数据，最终得到的模型预测结果的变化的量。高方差的模型会在测试集上出现很高的误差，通常是算法对于噪声过于敏感导致的，从而导致过拟合。过拟合指的是模型能够很好地拟合训练数据，但不能很好地泛化到测试数据。

![1760598867652](lecture8.assets/1760598867652.png)

![1760599487202](lecture8.assets/1760599487202.png)

其典型特征是预测误差在训练集和测试集上差异很大，在训练集上表现更好。可以通过增加训练数据，减少不相关的特征以及提前停止训练来改善。

### 估计方差和偏差

K 折交叉验证 (K-Fold Cross Validation) 是一种用于评估机器学习模型性能的技术。其过程是将数据集划分为 K 个子集，然后进行 K 次训练和测试。在每次迭代中，选择一个子集作为测试集，剩余的 K-1 个子集作为训练集。最终的模型性能是 K 次测试结果的平均值。

![1760599213659](lecture8.assets/1760599213659.png)

在 K 折交叉验证后，可以得到 k 个不同的预测误差 $e_1, e_2, \ldots, e_k$，得到 $\bar{e} = \frac{1}{k}\sum_{i=1}^k e_i$，以及标准差 $\sigma = \sqrt{\frac{1}{k}\sum_{i=1}^k(e_i - \bar{e})^2}$。得到的数据就是模型的偏差和方差的估计。

通常，偏差和方差是互相制约的。降低偏差通常会增加方差，反之亦然。这种权衡被称为偏差-方差权衡 (Bias-Variance Tradeoff)。在模型选择和调优过程中，需要在偏差和方差之间找到一个平衡点，以获得最佳的模型性能。

![1760599411788](lecture8.assets/1760599411788.png)

### 泛化 (Generalization)

泛化指的是模型将从训练集中学习到的内容应用到没有被学习过的数据上的能力。一个好的模型应该能够很好地泛化到新的数据，而不是仅仅记住训练数据。

![1760599671454](lecture8.assets/1760599671454.png)

## 数据准备

![1760599812051](lecture8.assets/1760599812051.png)

数据准备指的是没有结构的数据被转换成可以被机器学习算法使用的结构化数据的过程。数据准备通常包括

- 数据清理 (Data Cleaning)
  - 处理缺失值
  - 处理异常值
  - 处理重复数据
  - 处理不一致的数据

作用：

- 提高数据质量
  - 移除噪声、不一致性、错误
- 提高模型性能
  - 让模型更快的收敛，更准确
- 处理缺失数据
  - 使用差值或者删除防止模型产生偏差
- 减少过拟合
  - 特征选择和降维可以减小模型的复杂度
- 编码类别数据
  - 将类别数据转换为数值数据，便于模型处理
- 平衡类别分布
  - 解决不平衡数据集问题，防止模型偏向多数类
- 确认数据一致性
  - 对特征进行标准化，便于统一处理
- 节约计算资源
  - 预处理后的数据减少了计算量，提高效率

### 缺失值处理

缺失值有三种

- 完全随机缺失 (Missing Completely at Random, MCAR)
  - 缺失值的出现与数据的其他特征无关
  - 例子：问卷调查中，某些受访者随机跳过某些问题
  - 判断方式：Little's MCAR Test (使用统计检验来判断数据是否符合 MCAR 假设)
- 条件随机缺失 (Missing at Random, MAR)
  - 缺失值的出现与数据的其他特征有关，但与缺失值本身无关
  - 例子：在医疗数据中，某些患者的某些检查结果缺失，这可能与患者的年龄或性别有关
  - 判断方式：使用逻辑回归来预测缺失值的出现
- 非随机缺失 (Missing Not at Random, MNAR)
  - 缺失值的出现与缺失值本身有关
  - 例子：在收入调查中，收入较高的人可能更倾向于不报告他们的收入
  - 判断方式：通过领域知识和数据分析来识别
  
通常有两种处理方法：

- 数据移除
  - 当数据样本缺少某个数据时，删除样本
  - 损失值比例须小于 5%
  - 易于操作，但是可能会对 MAR 和 MNAR 的缺失引入偏差
- 值估计
  - 当数据样本缺少某个数据时，用估计值填充
  - 填充方法有：使用统计数据估计（如均值/中位数/众数），或者使用机器学习模型预测（如KNN）
  - 可以充分利用数据，但是可能会产生错误的数据

### 极端值处理

极端值指的是在数据集中显著偏离其他数据点的值。通常可以使用高斯分布或者近似高斯分布的Z分数 (Z-Score) 来检测极端值，或者使用高斯分布或者近似高斯分布的百分位矩/四分位矩方法 (IQR, Interquartile Range) 来检测极端值。

<!-- TODO: 61/104 -->
